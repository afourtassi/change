{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from collections import defaultdict\n",
    "from scipy import spatial\n",
    "from gensim.models import KeyedVectors\n",
    "from igraph import *\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(documents, dim=300, min_count=2, iters=100, window=5, negative=5):\n",
    "\tmodel = gensim.models.Word2Vec(\n",
    "        documents,\n",
    "        sg=1,\n",
    "        size=dim,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "#         max_final_vocab=3000,\n",
    "        sample=1e-5,\n",
    "        iter=iters,\n",
    "        ns_exponent=0.75,\n",
    "        negative=negative,\n",
    "        workers=4)\n",
    "\tmodel.train(documents, total_examples=len(documents), epochs=model.epochs)\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docs(csv_file, column='stem'):\n",
    "    \"\"\"read stem utterances from childes csv files\"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    tags = df['part_of_speech'].values\n",
    "    stems = df['stem'].values\n",
    "    ret_list = []\n",
    "    for t, s in zip(tags, stems):\n",
    "        tl, sl = str(t).lower().split(), str(s).lower().split()\n",
    "        \n",
    "        # replace NAME and interjections with $name$ and $co$ respectively\n",
    "        ntl = []\n",
    "        for t, s in zip(tl, sl):\n",
    "            if t == \"n:prop\":\n",
    "                ntl.append('$name$')\n",
    "#             elif t == 'co':\n",
    "#                 ntl.append('$co$')\n",
    "            else:\n",
    "                ntl.append(s)\n",
    "\n",
    "#         print(' '.join(ntl))\n",
    "        ret_list.append(ntl)\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/Users/hang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 675, 0, 2996, 15663, 17582, 25704, 43371, 2235, 12517, 59629, 26447, 87418, 41542, 64743, 73700, 88824, 129136, 141505, 137879, 126901, 123895, 119761, 167198, 154189, 156461, 186937, 234921, 219216, 160672, 149239, 132535, 134087, 104115, 144722, 103112, 89463, 107917, 91562, 63383, 55278, 73375, 73777, 96541, 74902, 60297, 101080, 51513, 61349, 58460, 39978, 37533, 52838, 45696, 36225, 611807, 33982, 47450, 32701, 19611, 21370, 22121, 30397, 17250, 31727, 42173, 26308, 30721, 22251, 18514, 8091, 6720, 2949, 593, 5993, 1607, 3155, 2907, 989, 1520, 1395, 7262, 7126, 16220, 10471, 9172, 18558, 14202, 15056, 19768, 9056, 1111, 793, 983, 313, 0, 1619, 565, 1677, 2296, 140, 933, 214, 121, 4442, 1450, 104, 7237, 4167, 5642, 9115, 3481, 9926, 6306, 12295, 11186, 1865, 2789, 8263, 5999, 2653, 4866, 0, 1711, 2579, 0, 0, 0, 477, 0, 2484, 1491, 0, 0, 0, 140, 0, 0, 845, 681, 0, 0, 667, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "childes_files = sorted(glob.glob(\"./data/childes/period*.csv\"))\n",
    "num_tokens = []\n",
    "for filename in sorted(childes_files, key=lambda x: int(x.split('_')[-1][:-4])):\n",
    "    month = int(filename.split('_')[-1][:-4])\n",
    "    lines = read_docs(filename)\n",
    "    num_tokens.append(sum([len(l) for l in lines]))\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098467 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22] 11.0\n",
      "1143362 [23, 24, 25, 26, 27, 28, 29] 26.0\n",
      "1044586 [30, 31, 32, 33, 34, 35, 36] 33.0\n",
      "1042200 [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49] 43.0\n",
      "1025318 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59] 54.5\n"
     ]
    }
   ],
   "source": [
    "window = []\n",
    "months = []\n",
    "periods = []\n",
    "\n",
    "for i, num in enumerate(num_tokens):\n",
    "    window.append(num)\n",
    "    months.append(i)\n",
    "    if sum(window) > 1000000:\n",
    "        periods.append(months)\n",
    "        print(sum(window), months, sum(months)/len(months))\n",
    "        window = []\n",
    "        months = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/childes/period_0.csv' './data/childes/period_1.csv'\n",
      " './data/childes/period_2.csv' './data/childes/period_3.csv'\n",
      " './data/childes/period_4.csv' './data/childes/period_5.csv'\n",
      " './data/childes/period_6.csv' './data/childes/period_7.csv'\n",
      " './data/childes/period_8.csv' './data/childes/period_9.csv'\n",
      " './data/childes/period_10.csv' './data/childes/period_11.csv'\n",
      " './data/childes/period_12.csv' './data/childes/period_13.csv'\n",
      " './data/childes/period_14.csv' './data/childes/period_15.csv'\n",
      " './data/childes/period_16.csv' './data/childes/period_17.csv'\n",
      " './data/childes/period_18.csv' './data/childes/period_19.csv'\n",
      " './data/childes/period_20.csv' './data/childes/period_21.csv'\n",
      " './data/childes/period_22.csv']\n",
      "key period0\n",
      "['./data/childes/period_23.csv' './data/childes/period_24.csv'\n",
      " './data/childes/period_25.csv' './data/childes/period_26.csv'\n",
      " './data/childes/period_27.csv' './data/childes/period_28.csv'\n",
      " './data/childes/period_29.csv']\n",
      "key period1\n",
      "['./data/childes/period_30.csv' './data/childes/period_31.csv'\n",
      " './data/childes/period_32.csv' './data/childes/period_33.csv'\n",
      " './data/childes/period_34.csv' './data/childes/period_35.csv'\n",
      " './data/childes/period_36.csv']\n",
      "key period2\n",
      "['./data/childes/period_37.csv' './data/childes/period_38.csv'\n",
      " './data/childes/period_39.csv' './data/childes/period_40.csv'\n",
      " './data/childes/period_41.csv' './data/childes/period_42.csv'\n",
      " './data/childes/period_43.csv' './data/childes/period_44.csv'\n",
      " './data/childes/period_45.csv' './data/childes/period_46.csv'\n",
      " './data/childes/period_47.csv' './data/childes/period_48.csv'\n",
      " './data/childes/period_49.csv']\n",
      "key period3\n",
      "['./data/childes/period_50.csv' './data/childes/period_51.csv'\n",
      " './data/childes/period_52.csv' './data/childes/period_53.csv'\n",
      " './data/childes/period_54.csv' './data/childes/period_55.csv'\n",
      " './data/childes/period_56.csv' './data/childes/period_57.csv'\n",
      " './data/childes/period_58.csv' './data/childes/period_59.csv']\n",
      "key period4\n",
      "[0, 0, 0, 675, 0, 2996, 15663, 17582, 25704, 43371, 2235, 12517, 59629, 26447, 87418, 41542, 64743, 73700, 88824, 129136, 141505, 137879, 126901, 123895, 119761, 167198, 154189, 156461, 186937, 234921, 219216, 160672, 149239, 132535, 134087, 104115, 144722, 103112, 89463, 107917, 91562, 63383, 55278, 73375, 73777, 96541, 74902, 60297, 101080, 51513, 61349, 58460, 39978, 37533, 52838, 45696, 36225, 611807, 33982, 47450, 32701, 19611, 21370, 22121, 30397, 17250, 31727, 42173, 26308, 30721, 22251, 18514, 8091, 6720, 2949, 593, 5993, 1607, 3155, 2907, 989, 1520, 1395, 7262, 7126, 16220, 10471, 9172, 18558, 14202, 15056, 19768, 9056, 1111, 793, 983, 313, 0, 1619, 565, 1677, 2296, 140, 933, 214, 121, 4442, 1450, 104, 7237, 4167, 5642, 9115, 3481, 9926, 6306, 12295, 11186, 1865, 2789, 8263, 5999, 2653, 4866, 0, 1711, 2579, 0, 0, 0, 477, 0, 2484, 1491, 0, 0, 0, 140, 0, 0, 845, 681, 0, 0, 667, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "childes_files = sorted(glob.glob(\"./data/childes/period*.csv\"), key=lambda x: int(x.split('_')[-1][:-4]))\n",
    "year2vecs = {}\n",
    "for i, period in enumerate(periods):\n",
    "    print(np.array(childes_files)[period])\n",
    "    print('key', 'period'+str(i))\n",
    "    docs = []\n",
    "    for filename in np.array(childes_files)[period]:\n",
    "        docs.extend(read_docs(filename))\n",
    "    model = train_word2vec(docs, dim=100, min_count=15, iters=50, window=5)\n",
    "    d = {w:v for w, v in zip(model.wv.index2word, model.wv.vectors)}\n",
    "    year2vecs['period'+str(i)] = d\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/embeddings-over-time/embeddings-English-NA-1M-ep50-f15.pickle', 'wb') as handle:\n",
    "    pickle.dump(year2vecs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
