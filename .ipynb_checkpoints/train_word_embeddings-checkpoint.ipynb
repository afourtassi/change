{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from collections import defaultdict\n",
    "from scipy import spatial\n",
    "from gensim.models import KeyedVectors\n",
    "from igraph import *\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(documents, dim=300, min_count=2, iters=100, window=5, negative=5):\n",
    "\tmodel = gensim.models.Word2Vec(\n",
    "        documents,\n",
    "        sg=1,\n",
    "        size=dim,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "#         max_final_vocab=3000,\n",
    "        sample=1e-5,\n",
    "        iter=iters,\n",
    "        ns_exponent=0.75,\n",
    "        negative=negative,\n",
    "        workers=4)\n",
    "\tmodel.train(documents, total_examples=len(documents), epochs=model.epochs)\n",
    "\treturn model\n",
    "\n",
    "def read_docs(csv_file, column='stem'):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    tags = df['part_of_speech'].values\n",
    "    stems = df['stem'].values\n",
    "    ret_list = []\n",
    "    for t, s in zip(tags, stems):\n",
    "        tl, sl = str(t).lower().split(), str(s).lower().split()\n",
    "        \n",
    "        # replace NAME and interjections with $name$ and $co$ respectively\n",
    "        ntl = []\n",
    "        for t, s in zip(tl, sl):\n",
    "            if t == \"n:prop\":\n",
    "                ntl.append('$name$')\n",
    "            elif t == 'co':\n",
    "                ntl.append('$co$')\n",
    "            else:\n",
    "                ntl.append(s)\n",
    "\n",
    "#         print(' '.join(ntl))\n",
    "        ret_list.append(ntl)\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/Users/hang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (11,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 675, 0, 2996, 15663, 17582, 25704, 43371, 2235, 18595, 73200, 93436, 109389, 62921, 80428, 93764, 194213, 153429, 161326, 189616, 222385, 281451, 574601, 499293, 515099, 532281, 505978, 548514, 670957, 565947, 469748, 501356, 464451, 405575, 776889, 313177, 205337, 230318, 154513, 155255, 259921, 169736, 139363, 188878, 154077, 146393, 195701, 127483, 113799, 109585, 124600, 97402, 198899, 129798, 88846, 660399, 76209, 94505, 65465, 46699, 40163, 34145, 37276, 33480, 84709, 67468, 34144, 40616, 27063, 28027, 15985, 17189, 14914, 14057, 9497, 9951, 9696, 16858, 12940, 16609, 6876, 30265, 26949, 38818, 20143, 18162, 19409, 16892, 22755, 29847, 10955, 6206, 9887, 13402, 1879, 2702, 3110, 5285, 2891, 3035, 4418, 2771, 4252, 340, 6896, 6225, 2122, 7346, 4187, 5699, 11342, 6588, 10035, 8916, 12356, 11844, 1925, 4827, 14867, 6036, 2715, 5008, 154, 1968, 2625, 39, 28, 27, 493, 74, 2514, 9475, 19, 6, 23, 151, 3801, 24, 2093, 681, 2, 11, 667, 0, 5070, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "childes_files = sorted(glob.glob(\"./childes_data/month*.csv\"))\n",
    "num_tokens = []\n",
    "for filename in sorted(childes_files, key=lambda x: int(x.split('_')[-1][:-4])):\n",
    "    month = int(filename.split('_')[-1][:-4])\n",
    "    lines = read_docs(filename)\n",
    "    num_tokens.append(sum([len(l) for l in lines]))\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148927 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] 10.0\n",
      "1268053 [21, 22, 23, 24] 22.5\n",
      "1014392 [25, 26] 25.5\n",
      "1038259 [27, 28] 27.5\n",
      "1219471 [29, 30] 29.5\n",
      "1035695 [31, 32] 31.5\n",
      "1371382 [33, 34, 35] 34.0\n",
      "1090066 [36, 37] 36.5\n",
      "1005344 [38, 39, 40, 41, 42] 40.0\n",
      "1121631 [43, 44, 45, 46, 47, 48, 49] 46.0\n",
      "1523328 [50, 51, 52, 53, 54, 55, 56, 57] 53.5\n",
      "1008287 [58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88] 73.0\n"
     ]
    }
   ],
   "source": [
    "window = []\n",
    "months = []\n",
    "periods = []\n",
    "\n",
    "for i, num in enumerate(num_tokens):\n",
    "    window.append(num)\n",
    "    months.append(i)\n",
    "    if sum(window) > 1000000:\n",
    "        periods.append(months)\n",
    "        print(sum(window), months, sum(months)/len(months))\n",
    "        window = []\n",
    "        months = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./childes_data/month_0_1.csv' './childes_data/month_1_2.csv'\n",
      " './childes_data/month_2_3.csv' './childes_data/month_3_4.csv'\n",
      " './childes_data/month_4_5.csv' './childes_data/month_5_6.csv'\n",
      " './childes_data/month_6_7.csv' './childes_data/month_7_8.csv'\n",
      " './childes_data/month_8_9.csv' './childes_data/month_9_10.csv'\n",
      " './childes_data/month_10_11.csv' './childes_data/month_11_12.csv'\n",
      " './childes_data/month_12_13.csv' './childes_data/month_13_14.csv'\n",
      " './childes_data/month_14_15.csv' './childes_data/month_15_16.csv'\n",
      " './childes_data/month_16_17.csv' './childes_data/month_17_18.csv'\n",
      " './childes_data/month_18_19.csv' './childes_data/month_19_20.csv'\n",
      " './childes_data/month_20_21.csv']\n",
      "key period0\n",
      "['./childes_data/month_21_22.csv' './childes_data/month_22_23.csv'\n",
      " './childes_data/month_23_24.csv' './childes_data/month_24_25.csv']\n",
      "key period1\n",
      "['./childes_data/month_25_26.csv' './childes_data/month_26_27.csv']\n",
      "key period2\n",
      "['./childes_data/month_27_28.csv' './childes_data/month_28_29.csv']\n",
      "key period3\n",
      "['./childes_data/month_29_30.csv' './childes_data/month_30_31.csv']\n",
      "key period4\n",
      "['./childes_data/month_31_32.csv' './childes_data/month_32_33.csv']\n",
      "key period5\n",
      "['./childes_data/month_33_34.csv' './childes_data/month_34_35.csv'\n",
      " './childes_data/month_35_36.csv']\n",
      "key period6\n",
      "['./childes_data/month_36_37.csv' './childes_data/month_37_38.csv']\n",
      "key period7\n",
      "['./childes_data/month_38_39.csv' './childes_data/month_39_40.csv'\n",
      " './childes_data/month_40_41.csv' './childes_data/month_41_42.csv'\n",
      " './childes_data/month_42_43.csv']\n",
      "key period8\n",
      "['./childes_data/month_43_44.csv' './childes_data/month_44_45.csv'\n",
      " './childes_data/month_45_46.csv' './childes_data/month_46_47.csv'\n",
      " './childes_data/month_47_48.csv' './childes_data/month_48_49.csv'\n",
      " './childes_data/month_49_50.csv']\n",
      "key period9\n",
      "['./childes_data/month_50_51.csv' './childes_data/month_51_52.csv'\n",
      " './childes_data/month_52_53.csv' './childes_data/month_53_54.csv'\n",
      " './childes_data/month_54_55.csv' './childes_data/month_55_56.csv'\n",
      " './childes_data/month_56_57.csv' './childes_data/month_57_58.csv']\n",
      "key period10\n",
      "['./childes_data/month_58_59.csv' './childes_data/month_59_60.csv'\n",
      " './childes_data/month_60_61.csv' './childes_data/month_61_62.csv'\n",
      " './childes_data/month_62_63.csv' './childes_data/month_63_64.csv'\n",
      " './childes_data/month_64_65.csv' './childes_data/month_65_66.csv'\n",
      " './childes_data/month_66_67.csv' './childes_data/month_67_68.csv'\n",
      " './childes_data/month_68_69.csv' './childes_data/month_69_70.csv'\n",
      " './childes_data/month_70_71.csv' './childes_data/month_71_72.csv'\n",
      " './childes_data/month_72_73.csv' './childes_data/month_73_74.csv'\n",
      " './childes_data/month_74_75.csv' './childes_data/month_75_76.csv'\n",
      " './childes_data/month_76_77.csv' './childes_data/month_77_78.csv'\n",
      " './childes_data/month_78_79.csv' './childes_data/month_79_80.csv'\n",
      " './childes_data/month_80_81.csv' './childes_data/month_81_82.csv'\n",
      " './childes_data/month_82_83.csv' './childes_data/month_83_84.csv'\n",
      " './childes_data/month_84_85.csv' './childes_data/month_85_86.csv'\n",
      " './childes_data/month_86_87.csv' './childes_data/month_87_88.csv'\n",
      " './childes_data/month_88_89.csv']\n",
      "key period11\n",
      "[0, 0, 0, 675, 0, 2996, 15663, 17582, 25704, 43371, 2235, 18595, 73200, 93436, 109389, 62921, 80428, 93764, 194213, 153429, 161326, 189616, 222385, 281451, 574601, 499293, 515099, 532281, 505978, 548514, 670957, 565947, 469748, 501356, 464451, 405575, 776889, 313177, 205337, 230318, 154513, 155255, 259921, 169736, 139363, 188878, 154077, 146393, 195701, 127483, 113799, 109585, 124600, 97402, 198899, 129798, 88846, 660399, 76209, 94505, 65465, 46699, 40163, 34145, 37276, 33480, 84709, 67468, 34144, 40616, 27063, 28027, 15985, 17189, 14914, 14057, 9497, 9951, 9696, 16858, 12940, 16609, 6876, 30265, 26949, 38818, 20143, 18162, 19409, 16892, 22755, 29847, 10955, 6206, 9887, 13402, 1879, 2702, 3110, 5285, 2891, 3035, 4418, 2771, 4252, 340, 6896, 6225, 2122, 7346, 4187, 5699, 11342, 6588, 10035, 8916, 12356, 11844, 1925, 4827, 14867, 6036, 2715, 5008, 154, 1968, 2625, 39, 28, 27, 493, 74, 2514, 9475, 19, 6, 23, 151, 3801, 24, 2093, 681, 2, 11, 667, 0, 5070, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "childes_files = sorted(glob.glob(\"./childes_data/month*.csv\"), key=lambda x: int(x.split('_')[-1][:-4]))\n",
    "year2vecs = {}\n",
    "for i, period in enumerate(periods):\n",
    "    print(np.array(childes_files)[period])\n",
    "    print('key', 'period'+str(i))\n",
    "    docs = []\n",
    "    for filename in np.array(childes_files)[period]:\n",
    "        docs.extend(read_docs(filename))\n",
    "    model = train_word2vec(docs, dim=100, min_count=15, iters=25, window=5)\n",
    "    d = {w:v for w, v in zip(model.wv.index2word, model.wv.vectors)}\n",
    "    year2vecs['period'+str(i)] = d\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./childes_data/embeddings-over-time/embeddings-over-time-vocabs-1M-ep25-f15.pickle', 'wb') as handle:\n",
    "    pickle.dump(year2vecs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
